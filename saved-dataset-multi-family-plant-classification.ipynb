{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12114558,"sourceType":"datasetVersion","datasetId":7627528},{"sourceId":12127628,"sourceType":"datasetVersion","datasetId":7636683},{"sourceId":12202574,"sourceType":"datasetVersion","datasetId":7686577}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ghousiah/saved-dataset-multi-family-plant-classification?scriptVersionId=246082204\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Start From Here if you have \"datasetforfivefamiliesplant**","metadata":{}},{"cell_type":"markdown","source":"### **Parameter Settings**","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:18:41.6475Z","iopub.execute_input":"2025-06-18T06:18:41.647683Z","iopub.status.idle":"2025-06-18T06:18:42.045013Z","shell.execute_reply.started":"2025-06-18T06:18:41.647665Z","shell.execute_reply":"2025-06-18T06:18:42.044352Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_size=96\nbatch_size=16","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:18:45.64496Z","iopub.execute_input":"2025-06-18T06:18:45.645212Z","iopub.status.idle":"2025-06-18T06:18:45.648684Z","shell.execute_reply.started":"2025-06-18T06:18:45.645195Z","shell.execute_reply":"2025-06-18T06:18:45.647923Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/datasetforfivefamiliesplant/filtered_cached.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:22:00.511274Z","iopub.execute_input":"2025-06-18T06:22:00.511556Z","iopub.status.idle":"2025-06-18T06:22:00.648615Z","shell.execute_reply.started":"2025-06-18T06:22:00.511536Z","shell.execute_reply":"2025-06-18T06:22:00.647969Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Manage Labels\n# Create new label mappings based on the 5 families\n#label_to_idx = {fam: i for i, fam in enumerate(sorted(df['family'].unique()))}\nlabel_to_idx = dict(zip(df['family'], df['label']))\n#-----------------------------------------------------------------------","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:22:24.845011Z","iopub.execute_input":"2025-06-18T06:22:24.845645Z","iopub.status.idle":"2025-06-18T06:22:24.850662Z","shell.execute_reply.started":"2025-06-18T06:22:24.845622Z","shell.execute_reply":"2025-06-18T06:22:24.849918Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":".","metadata":{}},{"cell_type":"markdown","source":"### **Prepare Training and Validation Dataset**","metadata":{}},{"cell_type":"code","source":"# Split dataset into Train and Validation Set\n\nfrom sklearn.model_selection import train_test_split\n\n# df is your full dataframe\ntrain_df, val_df = train_test_split(\n    df,\n    test_size=0.2,\n    stratify=df['label'],  # This keeps class proportions\n    random_state=42\n)\n\n\n\n#------------------------------------------------------","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:22:30.638974Z","iopub.execute_input":"2025-06-18T06:22:30.639625Z","iopub.status.idle":"2025-06-18T06:22:30.652601Z","shell.execute_reply.started":"2025-06-18T06:22:30.639604Z","shell.execute_reply":"2025-06-18T06:22:30.652038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sanity check\n\nprint(\"Training label distribution:\")\nprint(train_df['label'].value_counts(normalize=True))\nprint(\"\")\n\n\nprint(f\"Training samples after filtering: {len(train_df)}\")\nprint(f\"Unique families: {train_df['family'].unique()}\")\nprint(\"Number of samples per family:\")\nprint(train_df['family'].value_counts())\n\nprint(\"\\nValidation label distribution:\")\nprint(val_df['label'].value_counts(normalize=True))\n\n\nprint(f\"Validation samples after filtering: {len(val_df)}\")\nprint(f\"Unique families: {val_df['family'].unique()}\")\nprint(\"Number of samples per family:\")\nprint(val_df['family'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:22:43.850585Z","iopub.execute_input":"2025-06-18T06:22:43.851046Z","iopub.status.idle":"2025-06-18T06:22:43.862187Z","shell.execute_reply.started":"2025-06-18T06:22:43.851023Z","shell.execute_reply":"2025-06-18T06:22:43.861477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport requests\nfrom io import BytesIO\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport torch\nimport random\n\nclass PlantClefDataset(torch.utils.data.Dataset):\n    def __init__(self, df = df, transform=None , label_to_idx = label_to_idx):\n        self.df = df\n        self.df = df.reset_index(drop=True)\n        \n        self.transform = transform\n\n        # Create new label mappings based on the 5 families\n        self.label_to_idx = label_to_idx\n        self.idx_to_label = {i: fam for fam, i in label_to_idx.items()}\n        self.num_classes = len(self.label_to_idx)\n        \n    def __len__(self):\n        return len(self.df)\n\n\n    def __getitem__(self, idx):\n        path = self.df.loc[idx, 'cached_path']\n        label = self.df.loc[idx, 'label']\n        full_path = os.path.join('/kaggle/input/datasetforfivefamiliesplant/', path)\n    \n        try:\n            image = Image.open(full_path).convert('RGB')\n        except Exception as e:\n            print(f\"⚠️ Failed to open image: {full_path} — {e}\")\n            image = Image.new('RGB', (224, 224), (255, 255, 255))  # fallback white image\n\n        if self.transform:\n            image = self.transform(image)\n\n        # One-hot label\n        label_onehot = torch.zeros(self.num_classes)\n        label_onehot[label] = 1.0\n\n        return image, label_onehot\n\n\n#--------------------------------------------------------------------------------------------------\nfrom torchvision import transforms\n\nplant_transform = transforms.Compose([\n    transforms.Resize((400, 400)),\n    transforms.ToTensor(),  # Scales to [0, 1]\n\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:31:30.830288Z","iopub.execute_input":"2025-06-18T06:31:30.831114Z","iopub.status.idle":"2025-06-18T06:31:30.839429Z","shell.execute_reply.started":"2025-06-18T06:31:30.831078Z","shell.execute_reply":"2025-06-18T06:31:30.838842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checks - check if Class work properly\n\nplant_train = PlantClefDataset(train_df, transform=plant_transform)\nplant_val  = PlantClefDataset(val_df, transform=plant_transform)\n\n# Checks\nprint(f\"Number of classes in Training: {plant_train.num_classes}\")\nprint(\"Classes:\", plant_train.label_to_idx)\n\nprint(f\"Total samples after filtering: {len(plant_train.df)}\")\nprint(f\"Unique families: {plant_train.df['family'].unique()}\")\nprint(\"Number of samples per family:\")\nprint(plant_train.df['family'].value_counts())\n\nprint(f\"Number of classesin Validation: {plant_val.num_classes}\")\nprint(\"Classes:\", plant_val.label_to_idx)\n\nprint(f\"Total samples after filtering: {len(plant_val.df)}\")\nprint(f\"Unique families: {plant_val.df['family'].unique()}\")\nprint(\"Number of samples per family:\")\nprint(plant_val.df['family'].value_counts())\n\n\n# check if image can be loaded\nimport matplotlib.pyplot as plt\n\n# Visualize N images from dataset (no normalization involved)\ndef visualize_dataset(dataset, title='Sample Images', num_images=5):\n    plt.figure(figsize=(15, 3))\n    for i in range(num_images):\n        img_tensor, label_onehot = dataset[i]\n\n        # Convert tensor to HWC format and scale to [0, 255]\n        img = img_tensor.permute(1, 2, 0).numpy()\n        img = (img * 255).astype('uint8')\n\n        # Get label name from one-hot\n        label_idx = label_onehot.argmax().item()\n        label_name = dataset.idx_to_label[label_idx]\n\n        # Plot the image\n        plt.subplot(1, num_images, i+1)\n        plt.imshow(img)\n        plt.title(label_name)\n        plt.axis('off')\n    plt.suptitle(title)\n    plt.tight_layout()\n    plt.show()\n\n# Visualize training and validation datasets\nvisualize_dataset(plant_train, title=\"Training Samples\")\nvisualize_dataset(plant_val, title=\"Validation Samples\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:31:37.531797Z","iopub.execute_input":"2025-06-18T06:31:37.532493Z","iopub.status.idle":"2025-06-18T06:31:38.710221Z","shell.execute_reply.started":"2025-06-18T06:31:37.532471Z","shell.execute_reply":"2025-06-18T06:31:38.709568Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Preprocess Dataset - Prepare Quadrat Images for Training and Validation**","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom PIL import Image\nimport torch\nimport random\nfrom torch.utils.data import DataLoader\n\nclass QuadratDataset(Dataset):\n    def __init__(self, base_dataset, quad_size=4, transform=None):\n        self.base = base_dataset\n        self.quad_size = quad_size  # e.g. 4 for 2x2 grid\n        self.transform = transform\n        self.num_classes = self.base.num_classes\n\n    def __len__(self):\n        return len(self.base) // self.quad_size\n\n    def __getitem__(self, idx):\n        imgs, labels = [], []\n\n        for _ in range(self.quad_size):\n            # Randomly select a single-plant image and its one-hot label\n            img, lbl = self.base[random.randint(0, len(self.base) - 1)]\n            imgs.append(transforms.ToPILImage()(img))  # Convert back to PIL for stitching\n            labels.append(lbl)\n\n        # Assume all images same size, create blank 2x2 canvas\n        w, h = imgs[0].size\n        quad = Image.new('RGB', (w*2, h*2))\n\n        coords = [(0, 0), (w, 0), (0, h), (w, h)]\n        for img_patch, xy in zip(imgs, coords):\n            quad.paste(img_patch, xy)\n\n        if self.transform:\n            quad = self.transform(quad)\n\n        # Multi-label target (merge all 4 labels)\n        ml_label = torch.zeros(self.num_classes)\n        for lbl in labels:\n            ml_label = torch.logical_or(ml_label, lbl.bool()).float()\n\n        return quad, ml_label\n\n\nquadrat_transform = transforms.Compose([\n    transforms.Resize((img_size,img_size)),\n    transforms.ToTensor(),  # Scales to [0, 1]\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:31:50.500318Z","iopub.execute_input":"2025-06-18T06:31:50.500908Z","iopub.status.idle":"2025-06-18T06:31:50.50869Z","shell.execute_reply.started":"2025-06-18T06:31:50.500887Z","shell.execute_reply":"2025-06-18T06:31:50.50803Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create single-plant datasets\ntrain_base = PlantClefDataset(train_df, transform=plant_transform)\nval_base = PlantClefDataset(val_df, transform=plant_transform)\n\n# Create quadrat datasets for training and validation\nquadrat_train = QuadratDataset(train_base, quad_size=4, transform=quadrat_transform)\nquadrat_val = QuadratDataset(val_base, quad_size=4, transform=quadrat_transform)\n\ntrain_loader = DataLoader(quadrat_train, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(quadrat_val, batch_size=batch_size, shuffle=False, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:31:57.705534Z","iopub.execute_input":"2025-06-18T06:31:57.706229Z","iopub.status.idle":"2025-06-18T06:31:57.714449Z","shell.execute_reply.started":"2025-06-18T06:31:57.706205Z","shell.execute_reply":"2025-06-18T06:31:57.7138Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checks\nprint(f\"Total samples in quadrat_test: {len(quadrat_train)}\")\nprint(f\"Total samples in quadrat_test: {len(quadrat_val)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:32:00.120426Z","iopub.execute_input":"2025-06-18T06:32:00.120707Z","iopub.status.idle":"2025-06-18T06:32:00.124847Z","shell.execute_reply.started":"2025-06-18T06:32:00.120687Z","shell.execute_reply":"2025-06-18T06:32:00.124106Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checks\nimport matplotlib.pyplot as plt\nimport torchvision\nimport numpy as np\n\n# Get one batch from the training loader\nimages, labels = next(iter(train_loader))  # or val_loader\n\n# De-normalize helper (reverse normalization)\ndef denormalize(tensor):\n    mean = torch.tensor([0.485, 0.456, 0.406]).view(1,1,3)\n    std = torch.tensor([0.229, 0.224, 0.225]).view(1,1,3)\n    return tensor * std + mean\n\n# Plot the first few images with labels\nplt.figure(figsize=(16, 8))\nfor i in range(8):  # Show 8 samples\n    img = images[i].permute(1, 2, 0).detach().cpu()  # CHW -> HWC\n    img = denormalize(img).numpy()\n    img = np.clip(img, 0, 1)\n\n    # Get label indices\n    label_idxs = torch.nonzero(labels[i]).squeeze().tolist()\n    if isinstance(label_idxs, int): label_idxs = [label_idxs]\n\n    # Convert label indices to family names\n    label_names = [train_loader.dataset.base.idx_to_label[idx] for idx in label_idxs]\n\n    plt.subplot(2, 4, i+1)\n    plt.imshow(img)\n    plt.title(\", \".join(label_names), fontsize=9)\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:32:04.693296Z","iopub.execute_input":"2025-06-18T06:32:04.693991Z","iopub.status.idle":"2025-06-18T06:32:09.254869Z","shell.execute_reply.started":"2025-06-18T06:32:04.693965Z","shell.execute_reply":"2025-06-18T06:32:09.2541Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **MODEL**","metadata":{}},{"cell_type":"code","source":"import torch, timm\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import f1_score\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:32:15.343946Z","iopub.execute_input":"2025-06-18T06:32:15.344681Z","iopub.status.idle":"2025-06-18T06:32:18.80404Z","shell.execute_reply.started":"2025-06-18T06:32:15.344656Z","shell.execute_reply":"2025-06-18T06:32:18.803495Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = timm.create_model('efficientnet_lite0', pretrained=True, num_classes=quadrat_train.num_classes)\nfor p in model.parameters():\n    p.requires_grad = False\nfor p in model.get_classifier().parameters():\n    p.requires_grad = True\n\nmodel = model.to(device)\n\nloss_fn = nn.BCEWithLogitsLoss()\noptimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:32:23.505604Z","iopub.execute_input":"2025-06-18T06:32:23.506522Z","iopub.status.idle":"2025-06-18T06:32:24.33383Z","shell.execute_reply.started":"2025-06-18T06:32:23.506498Z","shell.execute_reply":"2025-06-18T06:32:24.333106Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checks\n\nmodel\n\nfrom torchinfo import summary\nsummary(model=model,\n        input_size=(1, 3, 96, 96),  # match model expected input size\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:32:31.630931Z","iopub.execute_input":"2025-06-18T06:32:31.631584Z","iopub.status.idle":"2025-06-18T06:32:32.341511Z","shell.execute_reply.started":"2025-06-18T06:32:31.631563Z","shell.execute_reply":"2025-06-18T06:32:32.340771Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **TRAINING**","metadata":{}},{"cell_type":"code","source":"import time \nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score\nimport copy\n\ndef train_model(model, train_loader, val_loader, optimizer, loss_fn, device, epochs=10, save_path='best_model.pth'):\n    train_losses = []\n    val_losses = []\n    best_f1 = 0.0\n    best_model_wts = copy.deepcopy(model.state_dict())\n\n    start_time = time.time()  # ⏱️ Start tracking total time\n\n    for epoch in range(epochs):\n        epoch_start = time.time()  # ⏱️ Time per epoch start\n        model.train()\n        total_loss = 0\n\n        for images, labels in train_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        avg_train_loss = total_loss / len(train_loader)\n        train_losses.append(avg_train_loss)\n\n        # Evaluate\n        val_loss, val_f1 = evaluate_model(model, val_loader, loss_fn, device)\n        val_losses.append(val_loss)\n\n        epoch_time = time.time() - epoch_start  # ⏱️ Time per epoch\n        print(f\"Epoch {epoch+1}/{epochs} | Time: {epoch_time:.2f}s | Train Loss: {avg_train_loss:.4f} | Val Loss: {val_loss:.4f} | Val F1: {val_f1:.4f}\")\n\n        # Save best model with epoch-based filename\n        if val_f1 > best_f1:\n            best_f1 = val_f1\n            best_model_wts = copy.deepcopy(model.state_dict())\n\n            # Save only model weights (optional)\n            best_model_filename = f\"best_model_epoch_{epoch+1}.pth\"\n            torch.save(best_model_wts, best_model_filename)\n\n            # Save full checkpoint (model + optimizer + epoch)\n            torch.save({\n                'epoch': epoch + 1,\n                'model_state_dict': best_model_wts,\n                'optimizer_state_dict': optimizer.state_dict(),\n                'val_loss': val_loss,\n                'val_f1': val_f1,\n            }, f\"checkpoint_epoch_{epoch+1}.pth\")\n\n            print(f\"✅ Best model saved as '{best_model_filename}'\")\n\n    # Save final checkpoint (last state)\n    torch.save({\n        'epoch': epochs,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n    }, 'final_checkpoint.pth')\n\n    print(\"✅ Final model checkpoint saved as 'final_checkpoint.pth'\")\n\n    total_time = time.time() - start_time  # ⏱️ Total time\n    print(f\"⏱️ Total training time: {total_time / 60:.2f} minutes\")\n\n    # Plot loss history\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(val_losses, label='Val Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training vs Validation Loss')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n    # Load best model weights into model for further use\n    model.load_state_dict(best_model_wts)\n\n\n\ndef evaluate_model(model, val_loader, loss_fn, device):\n    model.eval()\n    total_loss = 0\n    all_preds, all_trues = [], []\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)  # Already one-hot from dataset\n\n            outputs = model(images)\n            loss = loss_fn(outputs, labels)\n            total_loss += loss.item()\n\n            probs = torch.sigmoid(outputs).cpu().numpy()\n            preds = (probs > 0.5).astype(int)\n\n            all_preds.append(preds)\n            all_trues.append(labels.cpu().numpy())\n\n    y_pred = np.vstack(all_preds)\n    y_true = np.vstack(all_trues)\n    f1 = f1_score(y_true, y_pred, average='samples')  # multi-label F1\n    return total_loss / len(val_loader), f1\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:32:40.477096Z","iopub.execute_input":"2025-06-18T06:32:40.477631Z","iopub.status.idle":"2025-06-18T06:32:40.488708Z","shell.execute_reply.started":"2025-06-18T06:32:40.477609Z","shell.execute_reply":"2025-06-18T06:32:40.488001Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_model(model, train_loader, val_loader, optimizer, loss_fn, device, epochs=25)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T06:32:54.334Z","iopub.execute_input":"2025-06-18T06:32:54.334263Z","iopub.status.idle":"2025-06-18T07:02:57.462241Z","shell.execute_reply.started":"2025-06-18T06:32:54.334246Z","shell.execute_reply":"2025-06-18T07:02:57.46148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), 'final_model.pth')\nprint(\"💾 Final model saved as 'final_model.pth'.\")\n\ntorch.save({\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'epoch': 10,\n    # add any other training info here\n}, 'final_checkpoint.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T07:03:57.574808Z","iopub.execute_input":"2025-06-18T07:03:57.575102Z","iopub.status.idle":"2025-06-18T07:03:57.681076Z","shell.execute_reply.started":"2025-06-18T07:03:57.575078Z","shell.execute_reply":"2025-06-18T07:03:57.680258Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **EVALUATION**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score\nimport numpy as np\nimport torch\n\ndef evaluate_quadrats(model, quad_loader, idx_to_label, threshold=0.5, device='cuda'):\n    model.eval()\n    pred_bin_all = []\n    true_bin_all = []\n    pred_class_names_all = []\n    true_class_names_all = []\n\n    with torch.no_grad():\n        for images, labels in quad_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n            probs = torch.sigmoid(outputs).cpu().numpy()\n            preds_bin = (probs > threshold).astype(int)\n\n            pred_bin_all.extend(preds_bin)\n            true_bin_all.extend(labels.cpu().numpy())\n\n            # Convert predictions to class names\n            for pred_vec in preds_bin:\n                pred_classes = [idx_to_label[i] for i in range(len(pred_vec)) if pred_vec[i] == 1]\n                pred_class_names_all.append(pred_classes)\n\n            # Convert true labels to class names\n            for true_vec in labels.cpu().numpy():\n                true_classes = [idx_to_label[i] for i in range(len(true_vec)) if true_vec[i] == 1]\n                true_class_names_all.append(true_classes)\n\n    # Metrics\n    y_pred = np.vstack(pred_bin_all)\n    y_true = np.vstack(true_bin_all)\n\n    f1 = f1_score(y_true, y_pred, average='samples', zero_division=0)\n    precision = precision_score(y_true, y_pred, average='samples', zero_division=0)\n    recall = recall_score(y_true, y_pred, average='samples', zero_division=0)\n\n    print(f\"\\n📊 Evaluation Metrics:\")\n    print(f\"✅ F1 Score   : {f1:.4f}\")\n    print(f\"✅ Precision  : {precision:.4f}\")\n    print(f\"✅ Recall     : {recall:.4f}\\n\")\n\n    return pred_class_names_all, y_pred, y_true, true_class_names_all\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T07:04:03.624448Z","iopub.execute_input":"2025-06-18T07:04:03.625019Z","iopub.status.idle":"2025-06-18T07:04:03.632498Z","shell.execute_reply.started":"2025-06-18T07:04:03.624996Z","shell.execute_reply":"2025-06-18T07:04:03.631912Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred_class_names, pred_bin, true_bin, true_class_names = evaluate_quadrats(model, val_loader, plant_val.idx_to_label, threshold=0.5, device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T07:04:10.772734Z","iopub.execute_input":"2025-06-18T07:04:10.773443Z","iopub.status.idle":"2025-06-18T07:04:25.547834Z","shell.execute_reply.started":"2025-06-18T07:04:10.773421Z","shell.execute_reply":"2025-06-18T07:04:25.547044Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Show first N results (e.g., N=5)\nN = 5\nfor i in range(min(N, len(pred_class_names))):\n    print(f\"🟩 Sample {i+1}\")\n    print(\"✅ Predicted :\", pred_class_names[i])\n    print(\"🎯 Ground Truth:\", true_class_names[i])\n    print(\"-\" * 50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T07:05:03.297598Z","iopub.execute_input":"2025-06-18T07:05:03.297906Z","iopub.status.idle":"2025-06-18T07:05:03.303166Z","shell.execute_reply.started":"2025-06-18T07:05:03.297879Z","shell.execute_reply":"2025-06-18T07:05:03.302472Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\n\ndef denormalize(tensor):\n    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 1, 3)\n    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 1, 3)\n    return tensor * std + mean\n\nN = 5\nfor i in range(min(N, len(pred_class_names))):\n    # Get the quadrat image and label\n    img_tensor, _ = quadrat_val[i]  # image is CHW\n\n    # Denormalize\n    img = denormalize(img_tensor.permute(1, 2, 0))  # Convert to HWC and denormalize\n\n    # Clamp values to [0, 1] range in case of slight numerical overshoot\n    img = img.clamp(0, 1).numpy()\n\n    # Plot\n    plt.figure(figsize=(5, 5))\n    plt.imshow(img)\n    plt.axis('off')\n    plt.title(f\"Pred: {', '.join(pred_class_names[i])}\\n True: {', '.join(true_class_names[i])}\")\n    plt.show()\n\n    print(f\"🟩 Sample {i+1}\")\n    print(\"✅ Predicted :\", pred_class_names[i])\n    print(\"🎯 Ground Truth:\", true_class_names[i])\n    print(\"-\" * 50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T07:17:58.538011Z","iopub.execute_input":"2025-06-18T07:17:58.538571Z","iopub.status.idle":"2025-06-18T07:17:59.211267Z","shell.execute_reply.started":"2025-06-18T07:17:58.538551Z","shell.execute_reply":"2025-06-18T07:17:59.210563Z"}},"outputs":[],"execution_count":null}]}